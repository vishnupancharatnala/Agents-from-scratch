{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPR4EzINR1KYinO88SmKxW4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishnupancharatnala/Agents-from-scratch/blob/main/agents_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Agents works in Thought , Action and observation cycle\n",
        "#### 1) Thought :\n",
        "\n",
        "*   understanding the user request (requires natural understanding)\n",
        "*   Reasoning (thinking about what it can do)\n",
        "*   Planning to full fill the requirements\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#### 2) Action :\n",
        "\n",
        "\n",
        "*   interacting with enviroment to check what tools will full fill the task\n",
        "*   Invoking the tools\n",
        "\n",
        "#### 3) observation :\n",
        "\n",
        "\n",
        "*   Output of the LLM\n",
        "*   If the response is wrong or incorrect again it goes to thought\n",
        "*   If the response is correct it gives as output\n"
      ],
      "metadata": {
        "id": "JrMvfdogHT0Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Thought implementation**\n",
        "\n",
        "#### It's like brain of the agent ,it has to understand and reason accordingly\n",
        "#### we use an LLM for this purpose\n",
        "#### we have to give instructions in proper format\n",
        "#### for agent to think we have give in prompt to think step by step.\n",
        "\n",
        "#### for our agent we have to give prompt as\n",
        "#### 1)role\n",
        "#### 2)what it has to do\n",
        "#### 3)Tools available\n",
        "#### 4)thought action observation cycle\n"
      ],
      "metadata": {
        "id": "7S10uiX2HqJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "system_message=\"\"\"You are an AI assistant designed to help users efficiently and accurately. Your primary goal is to provide helpful, precise, and clear responses.\n",
        "\n",
        "You have access to the following tools:\n",
        "\n",
        "Tool Name: calculator, Description: Multiply two integers., Arguments: a: int, b: int, Output: int\n",
        "\n",
        "You should think tep by step in order to fulfill the objective with a reasoning divided into Thought/Action/Observation steps that can be repeated multiple times if needed.\n",
        "\n",
        "You should first reflect on the current situation using Thought: (your_thoughts)', then (if necessary), call a tool with the proper JSON formatting Action: (JSON_BLOB},\n",
        "or print your final answer starting with the prefix Final Answer:\"\"\""
      ],
      "metadata": {
        "id": "4N6e6TY4HrFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### The above is the format how we have to give instructions to agent.\n",
        "#### Thought will be done using React (reason and act)\n",
        "#### In the above if we observe for the tool we are manully giving Tool_name, description,arguments,output to invoke the tool\n",
        "#### If there are many tools this will become difficult\n",
        "#### using python introscopic function we can extract all these features from the function itself"
      ],
      "metadata": {
        "id": "meGIIOkwIKNa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# function to extract tool_name,description,arguments,output_type from the given function(tool)\n",
        "\n",
        "import inspect\n",
        "\n",
        "def extract_tool_info(func):\n",
        "    # Get the function signature\n",
        "    signature = inspect.signature(func)\n",
        "\n",
        "    # Extract (param_name, param_annotation) pairs for inputs\n",
        "    arguments = []\n",
        "    for param in signature.parameters.values():\n",
        "        annotation_name = (\n",
        "            param.annotation.__name__\n",
        "            if hasattr(param.annotation, '__name__')\n",
        "            else str(param.annotation)\n",
        "        )\n",
        "        arguments.append((param.name, annotation_name))\n",
        "\n",
        "    # To find the output type\n",
        "    return_annotation = signature.return_annotation\n",
        "    if return_annotation is inspect._empty:\n",
        "        outputs = \"No return annotation\"\n",
        "    else:\n",
        "        outputs = (\n",
        "            return_annotation.__name__\n",
        "            if hasattr(return_annotation, '__name__')\n",
        "            else str(return_annotation)\n",
        "        )\n",
        "\n",
        "    # extract the description\n",
        "    description = func.__doc__ or \"No description provided.\"\n",
        "\n",
        "    # extract tool name ...here function name becomes tool name\n",
        "    name = func.__name__\n",
        "\n",
        "    return f\"Tool Name: {name}, Description: {description}, Arguments: {arguments}, Output: {outputs}\"\n"
      ],
      "metadata": {
        "id": "-Ju6Y8KEKHoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def calculator(a: int, b: int) -> int:\n",
        "    \"\"\"Multiply two integers.\"\"\"\n",
        "    return a * b\n",
        "\n",
        "print(extract_tool_info(calculator))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxCSEpGwLuPB",
        "outputId": "add0d083-c085-4d2b-e17a-17556e2e1f31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tool Name: calculator, Description: Multiply two integers., Arguments: [('a', 'int'), ('b', 'int')], Output: int\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# but using the above function we have to manually pass the tool to the extract_tool_info function\n",
        "# instead of this we use a decorator and wrap the tool inside that decorator\n",
        "# inside the decorator we will all the tool info and pass this info to instance of Tool class where we write a method which we will invoke the function(tool) automatically\n",
        "\n",
        "from typing import Callable\n",
        "\n",
        "\n",
        "class Tool:\n",
        "    \"\"\"\n",
        "    A class representing a reusable piece of code (Tool).\n",
        "\n",
        "    Attributes:\n",
        "        name (str): Name of the tool.\n",
        "        description (str): A textual description of what the tool does.\n",
        "        func (callable): The function this tool wraps.\n",
        "        arguments (list): A list of argument.\n",
        "        outputs (str or list): The return type(s) of the wrapped function.\n",
        "    \"\"\"\n",
        "    def __init__(self,\n",
        "                 name: str,\n",
        "                 description: str,\n",
        "                 func: Callable,\n",
        "                 arguments: list,\n",
        "                 outputs: str):\n",
        "        self.name = name\n",
        "        self.description = description\n",
        "        self.func = func\n",
        "        self.arguments = arguments\n",
        "        self.outputs = outputs\n",
        "\n",
        "    def to_string(self) -> str:\n",
        "        \"\"\"\n",
        "        Return a string representation of the tool,\n",
        "        including its name, description, arguments, and outputs.\n",
        "        \"\"\"\n",
        "        args_str = \", \".join([\n",
        "            f\"{arg_name}: {arg_type}\" for arg_name, arg_type in self.arguments\n",
        "        ])\n",
        "\n",
        "        return (\n",
        "            f\"Tool Name: {self.name},\"\n",
        "            f\" Description: {self.description},\"\n",
        "            f\" Arguments: {args_str},\"\n",
        "            f\" Outputs: {self.outputs}\"\n",
        "        )\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        \"\"\"\n",
        "        Invoke the underlying function (callable) with provided arguments.\n",
        "        \"\"\"\n",
        "        return self.func(*args, **kwargs)"
      ],
      "metadata": {
        "id": "GdxZv__1OvOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculator_tool = Tool(\n",
        "    \"calculator\",                   # name\n",
        "    \"Multiply two integers.\",       # description\n",
        "    calculator,                     # function to call\n",
        "    [(\"a\", \"int\"), (\"b\", \"int\")],   # inputs (names and types)\n",
        "    \"int\",                          # output\n",
        ")"
      ],
      "metadata": {
        "id": "uzq1fBTWYt9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# decorator code\n",
        "import inspect\n",
        "\n",
        "def tool(func):\n",
        "    \"\"\"\n",
        "    A decorator that creates a Tool instance from the given function.\n",
        "    \"\"\"\n",
        "    # Get the function signature\n",
        "    signature = inspect.signature(func)\n",
        "\n",
        "    # Extract (param_name, param_annotation) pairs for inputs\n",
        "    arguments = []\n",
        "    for param in signature.parameters.values():\n",
        "        annotation_name = (\n",
        "            param.annotation.__name__\n",
        "            if hasattr(param.annotation, '__name__')\n",
        "            else str(param.annotation)\n",
        "        )\n",
        "        arguments.append((param.name, annotation_name))\n",
        "\n",
        "    # Determine the return annotation\n",
        "    return_annotation = signature.return_annotation\n",
        "    if return_annotation is inspect._empty:\n",
        "        outputs = \"No return annotation\"\n",
        "    else:\n",
        "        outputs = (\n",
        "            return_annotation.__name__\n",
        "            if hasattr(return_annotation, '__name__')\n",
        "            else str(return_annotation)\n",
        "        )\n",
        "\n",
        "    # Use the function's docstring as the description (default if None)\n",
        "    description = func.__doc__ or \"No description provided.\"\n",
        "\n",
        "    # The function name becomes the Tool name\n",
        "    name = func.__name__\n",
        "\n",
        "    # Return a new Tool instance\n",
        "    return Tool(\n",
        "        name=name,\n",
        "        description=description,\n",
        "        func=func,\n",
        "        arguments=arguments,\n",
        "        outputs=outputs\n",
        "    )"
      ],
      "metadata": {
        "id": "nkONH6ktYzqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@tool\n",
        "def calculator(a: int, b: int) -> int:\n",
        "    \"\"\"Multiply two integers.\"\"\"\n",
        "    return a * b\n",
        "\n",
        "print(calculator.to_string())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nsVdymzY5Cd",
        "outputId": "f48956e6-5eae-4e8d-d61f-d4bf6a4345db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tool Name: calculator, Description: Multiply two integers., Arguments: a: int, b: int, Outputs: int\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Action**\n",
        "#### we are done with thought part ,where it will understand the user query , reason,plan,interact with env\n",
        "#### now in the above system prompt we have seen giving agent the info about the tool\n",
        "#### Now after knowing which tool to use and extracting those details using python introscopic functions we want our agent to invoke the Tools\n",
        "#### Agent can't invoke the Tools directly, but it can generate the text so that the text is used to invoke the Tools. Tools are invoked by python controller\n",
        "#### Generating the text to invoke the Tools is called Action\n",
        "\n",
        "### For example :\n",
        "\n",
        "#### User gives input query:\n",
        "\n",
        "#### What is 6 times 7?\n",
        "\n",
        "#### Agent Reasoning Output\n",
        "\n",
        "```\n",
        "#The agent replies with:\n",
        "\n",
        "Thought: I need to multiply two numbers.\n",
        "Action:\n",
        "```json\n",
        "{\"tool\": \"calculator\", \"tool_input\": {\"a\": 6, \"b\": 7}}\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "#### it’s not literally calling a Python function — it's saying:\n",
        "\n",
        "#### “Hey, someone please run the calculator tool with a=6, b=7.”\n",
        "\n",
        "#### That’s exactly like an API request:\n",
        "\n",
        "#### The agent writes the request\n",
        "\n",
        "#### You (as the developer) or the framework plays the role of the API server\n",
        "\n",
        "#### The server reads the request, runs the logic, and sends back a response . Here Python Controller Executes It\n",
        "\n",
        "#### Now the python controller takes this json string(text) given by agent and parses it (converts json string to dictionary kind of json)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# code :\n",
        "import json\n",
        "\n",
        "json_text = '{\"tool\": \"calculator\", \"tool_input\": {\"a\": 6, \"b\": 7}}'\n",
        "\n",
        "#Parse it into a Python dict\n",
        "parsed = json.loads(json_text)\n",
        "print(parsed)\n",
        "\n",
        "Output: {'tool': 'calculator', 'tool_input': {'a': 6, 'b': 7}}\n",
        "\n",
        "#now we can use parsed['tool'] to get name of the tool\n",
        "\n",
        "# all the tools will be there in tools registary\n",
        "tools = ToolRegistry()\n",
        "tools.add_tool(calculator)\n",
        "\n",
        "#now python controller will look for the tool in the registary and call that tool\n",
        "\n",
        "tool_name = action[\"tool\"]\n",
        "tool_input = action[\"tool_input\"]\n",
        "\n",
        "#Look up the tool from registry\n",
        "tool_fn = tools.get_tool(tool_name)  # Returns the actual `calculator` function\n",
        "\n",
        "#Call the function\n",
        "result = tool_fn(**tool_input)  # result = calculator(a=6, b=7) => 42\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9LqcyBR_IcWw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Observation**  \n",
        "#### now the python controller will pass the output of the Tool to agent as observation\n",
        "#### Observation: 42\n",
        "\n",
        "#### Now the agent continues reasoning:\n",
        "\n",
        "\n",
        "```\n",
        "Thought: Now I know the result of 6 * 7.\n",
        "Final Answer: The result is 42.\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "#### 🧠 So to be super clear:\n",
        "\n",
        "#### The agent never calls a Python function. It only outputs JSON saying “I want to use tool X with arguments Y”.\n",
        "\n",
        "#### Your Python controller must:\n",
        "\n",
        "#### Parse that JSON.\n",
        "\n",
        "#### Look up the right tool.\n",
        "\n",
        "#### Call it.\n",
        "\n",
        "#### Return the result as an Observation.\n",
        "\n",
        "# flow of the agent\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "83gboJwoKKRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "+-------------------+\n",
        "|   User Input      |\n",
        "|  \"6 times 7?\"     |\n",
        "+---------+---------+\n",
        "          |\n",
        "          v\n",
        "+-------------------------------+\n",
        "|       Agent Model             |\n",
        "| - Receives system prompt      |\n",
        "| - Thinks using tools          |\n",
        "+-------------------------------+\n",
        "          |\n",
        "          | Text output:\n",
        "          v\n",
        "   Thought: I need to multiply...\n",
        "   Action: \"{\"tool\": \"calculator\", \"tool_input\": {\"a\": 6, \"b\": 7}}\"\n",
        "\n",
        "          |\n",
        "          v\n",
        "+-------------------------------+\n",
        "|     Python Controller         |\n",
        "| - Parses JSON                 |\n",
        "| - Finds tool                  |\n",
        "| - Calls calculator(6, 7)      |\n",
        "| - Gets result = 42            |\n",
        "+-------------------------------+\n",
        "          |\n",
        "          v\n",
        "Text injected back to agent:\n",
        "Observation: 42\n",
        "\n",
        "Then agent may say:\n",
        "Final Answer: 42\n",
        "\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "1QeB9G77KrQY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "| Step              | What Happens                                | Who Does It       |\n",
        "| ----------------- | ------------------------------------------- | ----------------- |\n",
        "| Tool Definition   | You define tool functions and decorate them | Developer (you)   |\n",
        "| Tool Registration | Tools are added to registry                 | Framework / You   |\n",
        "| Prompt Generation | Tool info is added to system message        | Framework         |\n",
        "| Reasoning         | Agent generates `Thought` and `Action`      | Agent model       |\n",
        "| Tool Execution    | JSON parsed, tool invoked                   | Python controller |\n",
        "| Result Injected   | `Observation` added back to agent           | Python controller |\n",
        "| Final Answer      | Agent produces answer using tool result     | Agent model       |\n",
        "\n",
        "\n",
        "<br>\n",
        "\n",
        "---\n",
        "<br>\n",
        "<br>\n"
      ],
      "metadata": {
        "id": "ngO1_hpvKhmb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Q3: What is a Python Controller?\n",
        "#### This is very important.\n",
        "#### A Python controller is the logic in your program that manages the whole agent loop.\n",
        "#### It does things like:\n",
        "#### Sends the user’s input to the agent model.\n",
        "#### Gets back the agent’s response.\n",
        "#### If the agent outputs Action: {...}, it:\n",
        "#### Parses the JSON\n",
        "#### Finds the tool (function)\n",
        "#### Calls the tool\n",
        "#### Gets the result\n",
        "#### Sends it back as Observation: ...\n",
        "#### Repeats until the agent gives a Final Answer."
      ],
      "metadata": {
        "id": "NnbDjNOBLTIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pseudo-controller for demonstration purpose\n",
        "def agent_loop(user_input):\n",
        "    context = []  # Chat history\n",
        "\n",
        "    while True:\n",
        "        # 1. Send context to agent\n",
        "        response = agent_model.generate(context + [user_input])\n",
        "\n",
        "        if response.startswith(\"Final Answer:\"):\n",
        "            print(response)\n",
        "            break\n",
        "\n",
        "        elif response.startswith(\"Action:\"):\n",
        "            # 2. Extract JSON from the Action:\n",
        "            json_block = extract_json(response)\n",
        "            action = json.loads(json_block)\n",
        "\n",
        "            tool_name = action[\"tool\"]\n",
        "            tool_args = action[\"tool_input\"]\n",
        "\n",
        "            # 3. Call tool\n",
        "            tool_fn = registry.get_tool(tool_name)\n",
        "            result = tool_fn(**tool_args)\n",
        "\n",
        "            # 4. Add tool result as Observation\n",
        "            observation = f\"Observation: {result}\"\n",
        "            context.append(response)  # Agent's action\n",
        "            context.append(observation)\n",
        "\n",
        "        else:\n",
        "            # Unexpected response\n",
        "            print(\"Unexpected agent output:\", response)\n",
        "            break\n"
      ],
      "metadata": {
        "id": "sjdZvxFNAFXN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Complete agent code from scratch**\n",
        "####  🔧 What We're Building\n",
        "#### ✅ A calculator(a, b) tool (you already have it)\n",
        "#### ✅ A full agent prompt (LLM system prompt)\n",
        "#### ✅ LLM call to generate Thought + Action (we stop before Observation:)\n",
        "#### ✅ Controller executes tool call\n",
        "#### ✅ Add the real observation\n",
        "#### ✅ Continue LLM generation to get final answer\n",
        "\n"
      ],
      "metadata": {
        "id": "EE2ylpIcLuBS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###########################    1. Tool Setup\n",
        "# in tools.py\n",
        "from typing import Callable\n",
        "import inspect\n",
        "\n",
        "class Tool:\n",
        "    def __init__(self, name: str, description: str, func: Callable, arguments: list, outputs: str):\n",
        "        self.name = name\n",
        "        self.description = description\n",
        "        self.func = func\n",
        "        self.arguments = arguments\n",
        "        self.outputs = outputs\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return self.func(*args, **kwargs)\n",
        "\n",
        "\n",
        "def tool(func):\n",
        "    signature = inspect.signature(func)\n",
        "    arguments = [\n",
        "        (param.name, param.annotation.__name__) for param in signature.parameters.values()\n",
        "    ]\n",
        "    return_type = signature.return_annotation.__name__ if signature.return_annotation else \"Any\"\n",
        "    return Tool(name=func.__name__, description=func.__doc__, func=func, arguments=arguments, outputs=return_type)\n",
        "\n",
        "\n",
        "@tool\n",
        "def calculator(a: int, b: int) -> int:\n",
        "    \"\"\"Multiply two integers.\"\"\"\n",
        "    return a * b\n"
      ],
      "metadata": {
        "id": "WpEyzjTALfnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "################################## 🧠 2. System Prompt (LLM Instruction)\n",
        "\n",
        "# in prompts.py\n",
        "SYSTEM_PROMPT = \"\"\"Answer the following questions as best you can. You have access to the following tools:\n",
        "\n",
        "calculator: Multiply two integers. args: {\"a\": {\"type\": \"int\"}, \"b\": {\"type\": \"int\"}}\n",
        "\n",
        "The way you use the tools is by specifying a json blob.\n",
        "Specifically, this json should have an `action` key (with the name of the tool to use) and an `action_input` key (with the tool's inputs).\n",
        "\n",
        "Use ONLY the following format:\n",
        "\n",
        "Question: the input question you must answer\n",
        "Thought: you should always think about one action to take\n",
        "Action:\n",
        "\n",
        "```json\n",
        "{\n",
        "  \"action\": \"calculator\",\n",
        "  \"action_input\": { \"a\": 6, \"b\": 7 }\n",
        "}\n",
        "\n",
        "Observation: the result of the action. This Observation is unique, complete, and the source of truth.\n",
        "\n",
        "... (repeat Thought/Action/Observation as needed)\n",
        "\n",
        "You must always end your output with the following format:\n",
        "\n",
        "Thought: I now know the final answer\n",
        "Final Answer: the final answer to the original input question\n",
        "\n",
        "Now begin! Reminder to ALWAYS use the exact characters Final Answer: when you provide a definitive answer.\"\"\"\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "eJbKbCXNLno7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#################################### 🤖 3. LLM Generation\n",
        "#  in agent_llm.py\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
        "from prompts import SYSTEM_PROMPT\n",
        "\n",
        "# LLaMA-style tokenizer (use another if you prefer)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-3-8B-Instruct\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Llama-3-8B-Instruct\", device_map=\"auto\")\n",
        "\n",
        "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "def build_prompt(user_question: str):\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "        {\"role\": \"user\", \"content\": user_question},\n",
        "    ]\n",
        "    return tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "\n",
        "\n",
        "def get_llm_action(prompt):\n",
        "    response = pipe(prompt, max_new_tokens=200, stop=[\"Observation:\"], return_full_text=False)[0][\"generated_text\"]\n",
        "    return response\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrX6Y9xQL9bD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##################################### 🕹️ 4. Controller to Run Tool\n",
        "# in controller.py\n",
        "\n",
        "import json\n",
        "import re\n",
        "from tools import calculator\n",
        "from agent_llm import build_prompt, get_llm_action\n",
        "\n",
        "TOOLS = {\n",
        "    \"calculator\": calculator,\n",
        "}\n",
        "\n",
        "def extract_json_block(text):\n",
        "    # Get JSON inside ```json block\n",
        "    match = re.search(r\"```json\\s*({.*?})\\s*```\", text, re.DOTALL)\n",
        "    if match:\n",
        "        return json.loads(match.group(1))\n",
        "    raise ValueError(\"No JSON action block found\")\n",
        "\n",
        "\n",
        "def run_agent(question):\n",
        "    # STEP 1: Create full prompt\n",
        "    base_prompt = build_prompt(question)\n",
        "\n",
        "    # STEP 2: Ask model what to do (up to Action)\n",
        "    print(\"\\n>>> LLM Generating Thought + Action ...\")\n",
        "    response = get_llm_action(base_prompt)\n",
        "    print(response)\n",
        "\n",
        "    # STEP 3: Parse JSON and run tool\n",
        "    parsed = extract_json_block(response)\n",
        "    tool_name = parsed[\"action\"]\n",
        "    tool_input = parsed[\"action_input\"]\n",
        "    result = TOOLS[tool_name](**tool_input)\n",
        "\n",
        "    print(f\"\\n>>> Tool Output (Observation): {result}\")\n",
        "\n",
        "    # STEP 4: Build new prompt with Observation and continue\n",
        "    final_prompt = base_prompt + response + f\"\\nObservation: {result}\\n\"\n",
        "    final_response = get_llm_action(final_prompt)\n",
        "\n",
        "    print(\"\\n>>> Final Output:\")\n",
        "    print(final_response)\n"
      ],
      "metadata": {
        "id": "PgBtWXkXMRRp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "####################################### 🚀 5. Run the System\n",
        "# in main.py\n",
        "from controller import run_agent\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_agent(\"What is 6 times 7?\")"
      ],
      "metadata": {
        "id": "HV_ROMPUMcWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Final Output Should Look Like:\n",
        "\n",
        "# >>> LLM Generating Thought + Action ...\n",
        "#\n",
        "# Thought: I need to multiply 6 and 7 to get the answer.\n",
        "# Action:\n",
        "# ```json\n",
        "# {\n",
        "  # \"action\": \"calculator\",\n",
        "  # \"action_input\": {\n",
        "    # \"a\": 6,\n",
        "    # \"b\": 7\n",
        "  # }\n",
        "# }\n",
        "\n",
        "# Tool Output (Observation): 42\n",
        "\n",
        "# Final Output:\n",
        "# Thought: I now know the final answer.\n",
        "# Final Answer: 42"
      ],
      "metadata": {
        "id": "7-NAmTn5NIp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "## ✅ Summary\n",
        "\n",
        " | Component         | Purpose |\n",
        " |------------------|---------|\n",
        " | `tools.py`       | Tool definition (`calculator`) |\n",
        " | `prompts.py`     | LLM system prompt |\n",
        " | `agent_llm.py`   | Prompt builder + first step of LLM generation |\n",
        " | `controller.py`  | Executes reasoning cycle, extracts tool calls, and handles real observations |\n",
        " | `main.py`        | Entry point |\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "qSXAoV0vMGiN"
      }
    }
  ]
}